from fastapi import APIRouter
from pydantic import BaseModel
from utils.youtube import search_youtube_videos
from utils.prompt import build_prompt, search_bm25_only, print_watsonx_response    #search_recipe_with_filters
import config
import time
from utils.watsonx import ask_watsonx, parse_watsonx_json
from typing import Optional, List
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlencode

router = APIRouter()

# âœ… POST ìš”ì²­ ë°”ë””
class RecipeRequest(BaseModel):
    ingredients: List[str] #list[str] 
    diseases: Optional[List[str]] = None
    allergies: Optional[List[str]] = None
    preference: Optional[str] = None
    kind: Optional[str] = None  
    level: Optional[str] = None  



def fetch_thumbnail_by_title(title: str) -> dict:
    try:
        base_url = "https://www.10000recipe.com/recipe/list.html"
        params = {"q": title, "order": "accuracy"}  # order=accuracyë¡œ ê³ ì •
        url = f"{base_url}?{urlencode(params)}"

        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/114.0.0.0 Safari/537.36"
            )
        }

        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        # ì—¬ëŸ¬ ê°œ ì¹´ë“œ ì¤‘ì—ì„œ icon_vodê°€ ì•„ë‹Œ ì²« ë²ˆì§¸ ì¹´ë“œ ì‚¬ìš©
        cards = soup.select("ul.common_sp_list_ul > li.common_sp_list_li")
        for card in cards:
            img_tag = card.select_one(".common_sp_thumb img")
            link_tag = card.select_one("a.common_sp_link")

            img_url = img_tag["src"] if img_tag else ""
            recipe_url = "https://www.10000recipe.com" + link_tag["href"] if link_tag else ""

            if "icon_vod.png" not in img_url:
                return {"image": img_url, "link": recipe_url}
            else:
                print(f"â© [{title}] ë™ì˜ìƒ ì¸ë„¤ì¼ ê±´ë„ˆëœ€: {img_url}")

        # ì¼ë°˜ ì¸ë„¤ì¼ ì—†ìœ¼ë©´ ë¹ˆ ê°’ ë¦¬í„´
        return {"image": "", "link": ""}

    except Exception as e:
        print(f"âŒ [{title}] ì¸ë„¤ì¼ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return {"image": "", "link": ""}

    
# âœ… ê¸°ì¡´ ìš”ì•½ + ìœ íŠœë¸Œ
@router.post("/recommend")
async def recommend_recipe(req: RecipeRequest):
    #vectordb_recipe = config.vector_db_recipe
    vectordb_disease = config.vector_db_disease
    #model = config.embedding_model
    bm25_retriever = config.bm25_retriever
    #faiss_loaded = config.faiss_loaded     

    ingredients_raw = req.ingredients or []
    diseases = req.diseases or []
    allergies = req.allergies or []
    preference = req.preference or ""
    kind = req.kind or ""
    level = req.level or ""

    # ì•ŒëŸ¬ì§€ì— "ë‹¬ê±€" ë˜ëŠ” "ê³„ë€"ì´ ìˆìœ¼ë©´ ë‘˜ ë‹¤ ì œì™¸, "ìƒˆìš°" ë˜ëŠ” "ëŒ€í•˜"ë„ ë§ˆì°¬ê°€ì§€
    egg_aliases = {"ë‹¬ê±€", "ê³„ë€"}
    shrimp_aliases = {"ìƒˆìš°", "ëŒ€í•˜"}

    # ì•ŒëŸ¬ì§€ì— ë‹¬ê±€/ê³„ë€ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ingredientsì—ì„œ ë‘˜ ë‹¤ ì œì™¸
    exclude_eggs = any(a in egg_aliases for a in allergies)
    exclude_shrimps = any(a in shrimp_aliases for a in allergies)

    ingredients = []
    for item in ingredients_raw:
        if exclude_eggs and item in egg_aliases:
            continue
        if exclude_shrimps and item in shrimp_aliases:
            continue
        if item in allergies:
            continue
        ingredients.append(item)

    print(f"ğŸ” Ingredients received: {ingredients}")
    print(f"âš•ï¸ ì§ˆí™˜ ì •ë³´: {diseases}")
    print(f"ğŸš« ì•ŒëŸ¬ì§€ ì •ë³´: {allergies}")
    print(f"ğŸ¥— ì‹ë‹¨ ì„ í˜¸: {preference}")
    print(f"ğŸ¥— ì¢…ë¥˜: {kind}")
    print(f"ğŸ¥— ë‚œì´ë„: {level}")

    # âœ… í›„ë³´ ë ˆì‹œí”¼ ê²€ìƒ‰ (ì¿¼ë¦¬ìš© ë¬¸ìì—´ ì¬ì¡°í•©, Top 50)
    # í•„í„° ìƒì„± (ë¹ˆ ê°’ì€ ì œì™¸)
    filters = {}
    if level:
        filters["ë‚œì´ë„"] = level
    if kind:
        filters["ì¢…ë¥˜"] = kind

    top_k = 50
    start = time.time()
    # filtered_recipes = search_recipe_with_filters(
    #    query=ingredients,
    #    bm25_retriever=bm25_retriever,
    #    faiss_loaded=faiss_loaded,
    #    filters=filters,
    #    top_k=top_k)
    filtered_recipes = search_bm25_only(
        query=ingredients,
        bm25_retriever=bm25_retriever,
        filters=filters,
        top_k=top_k
    )

    #     # filtered_recipesë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„±
    # filtered_recipes = []
    # for i, (doc, _) in enumerate(results):
    #     meta = doc.metadata
    #     filtered_recipes.append({
    #         "id": i+1,
    #         "ì œëª©": meta.get("ì œëª©", ""),
    #         "ì¬ë£Œ": [ing.strip() for ing in meta.get("ì¬ë£Œ", "").split(",") if ing.strip()],
    #         "URL": meta.get("URL", "")
    #     })

    print(f"ğŸ” ìœ ì‚¬ ë ˆì‹œí”¼ {top_k}ê°œ ê²€ìƒ‰ ì™„ë£Œ (ì†Œìš”: {time.time() - start:.2f}ì´ˆ)")
    print(f"ğŸ” ìœ ì‚¬ ë ˆì‹œí”¼: {filtered_recipes[:20]}")
    context = ""

    # âœ… ê´€ë ¨ disease context ì¶”ì¶œ
    if diseases:
        results = []
        for disease in diseases:
            query = f"{disease}ì˜ ì‹ì‚¬ìš”ë²•"
            result = vectordb_disease.similarity_search_with_score(query, k=1)
            results.extend(result)
        context = "\n\n".join([doc.page_content for doc, _ in results])
    else:
        context = None

    print(context)

    # Build prompt
    prompt = build_prompt(ingredients=ingredients, 
                        filtered_recipes = filtered_recipes, 
                        context=context, 
                        diseases=diseases,
                        allergies=allergies,
                        preference=preference
                        )

    print(f"ğŸ” Prompt built: {prompt[:1000]}")  # Print first 200 characters of prompt for debugging

    
    # Ask Watsonx
    ai_response = ask_watsonx(prompt)
    parsed = parse_watsonx_json(ai_response)
    print(f"ğŸ§  Watsonx ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
    print(f"ğŸ” Watsonx response: {ai_response}\n")
    print("íŒŒì‹± ê²°ê³¼:", parsed)

    # cursor ìˆ˜ì • - Watson ì‘ë‹µ ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
    if not parsed or "recommended_recipes" not in parsed:
        print(f"âŒ Watson ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ì˜ˆìƒ í˜•ì‹ì´ ì•„ë‹˜: {parsed}")
        return {
            "result": {
                "recommended_recipes": [],
                "dietary_tips": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        }
    
    # YouTube links
    # youtube_links = search_youtube_videos(ingredients)  # ì¬ë£Œ ëŒ€ì‹  ìš”ë¦¬ ì œëª©ë„ ê°€ëŠ¥
    # print(fğŸ” YouTube links: {youtube_links}")
    
    for recipe in parsed["recommended_recipes"]:
        title = recipe.get("ì œëª©", "")  # WatsonX ì‘ë‹µì—ì„œ "ì œëª©" ì‚¬ìš©
        if title:
            thumbnail_info = fetch_thumbnail_by_title(title)
            recipe["image"] = thumbnail_info["image"]
            recipe["link"] = thumbnail_info["link"]
            print(f"ğŸ“¸ {title} ì¸ë„¤ì¼: {thumbnail_info['image']}")
        else:
            recipe["image"] = ""
            recipe["link"] = ""

    return {
        "result": parsed
        
    }

